{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bee07a5",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- Allow resolution change to saved images to save space.\n",
    "- Pass language to Whisper???\n",
    "- Change from Whisper to Facebook's fairseq MMC? https://github.com/facebookresearch/fairseq/tree/main/examples/mms\n",
    "- Detect language, if Japanese add Furigana\n",
    "- Make sure device supports GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f2aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steph\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Steph\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\whisper\\timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import whisper\n",
    "import torch\n",
    "import moviepy.editor as mp\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import subprocess\n",
    "from datetime import timedelta\n",
    "from yattag import Doc\n",
    "import time\n",
    "\n",
    "\n",
    "ADD_FURIGANA = True\n",
    "VID_EXTS = ['.mp4','.avi','.ogv','.mkv','.webm']\n",
    "AUD_EXTS = ['.mp3']\n",
    "SUB_EXTS = ['.srt']\n",
    "WIDTH = 200\n",
    "src_dir = 'Input'\n",
    "out_dir = 'Output'\n",
    "files = [os.path.join(src_dir, f) for f in os.listdir(src_dir)]\n",
    "\n",
    "if ADD_FURIGANA:\n",
    "    from furigana.furigana import split_furigana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36734dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Input\\\\2023年6月10日（土）「OK! Cozy up!週末増刊号」']\n"
     ]
    }
   ],
   "source": [
    "proj_files = [os.path.splitext(f)[0] for f in files if os.path.splitext(f)[-1] in VID_EXTS]\n",
    "\n",
    "# Add audio files if they weren't extracted from a video with the same name\n",
    "proj_files += [os.path.splitext(f)[0] for f in files if os.path.splitext(f)[-1] in AUD_EXTS and os.path.splitext(f)[0] not in proj_files]\n",
    "print(proj_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30b6082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_line_list(filename, encoding='utf-8-sig'):\n",
    "        line_list = []\n",
    "        with open(filename, 'r', encoding=encoding) as file:\n",
    "            for line in file:\n",
    "                line_list += [line.replace('\\n', '')]\n",
    "        return line_list\n",
    "\n",
    "def chunk_sub_idx_to_list(sub_line_list):\n",
    "        \"\"\"\n",
    "            Pass in a list where each line is a line in the subtitle file\n",
    "            Example:\n",
    "            ['1', '00:00:00,000 --> 00:00:04,430', 'おはようございます', '2', ...]\n",
    "\n",
    "            return a list where each list item is another list where each item is specific to its index\n",
    "            Example:\n",
    "            [['1', '00:00:00,000 --> 00:00:04,430', 'おはようございます'], ['2', ...], ...]\n",
    "        \"\"\"\n",
    "        lines_indexed = []\n",
    "        tmp = []\n",
    "        for i, line in enumerate(sub_line_list):\n",
    "            if line == '':\n",
    "                continue\n",
    "\n",
    "            tmp += [line]\n",
    "            if len(tmp) > 3:\n",
    "                digit, timestamp = tmp[-2:]\n",
    "                if digit.strip().isdigit() and '-->' in timestamp:\n",
    "                    lines_indexed += [tmp[:-2]]\n",
    "                    tmp = tmp[-2:]\n",
    "        return lines_indexed\n",
    "    \n",
    "def srt_time_to_seconds(time_line):\n",
    "    def timestr_to_sec(time_str):\n",
    "        h, m, s_str = time_str.split(':')\n",
    "        s, ms = s_str.split(',')\n",
    "        return int(h)*60*60 + int(m)*60 + int(s) + int(ms)/1000 \n",
    "\n",
    "    start_time_str, stop_time_str = time_line.split(' --> ')\n",
    "    start_time = timestr_to_sec(start_time_str)\n",
    "    stop_time = timestr_to_sec(stop_time_str)\n",
    "\n",
    "    return start_time, stop_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a33025bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image(doc, image, idx, w=200, h=200):\n",
    "    basename = os.path.splitext(os.path.basename(image))[0]\n",
    "    with doc.tag('img', id=f'image_{idx}', src=image, alt=basename, width=w, height=h, klass=\"center\"):\n",
    "        pass # No content within this tag\n",
    "\n",
    "def add_audio_clip(doc, audio_file, idx):\n",
    "    with doc.tag('audio', controls=True, klass=\"center\"):\n",
    "        doc.stag('source', src=os.path.basename(audio_file), type=\"audio/mpeg\")\n",
    "        doc.text('Your browser does not support the audio element.')\n",
    "\n",
    "def add_sub(doc, sub):\n",
    "    with doc.tag('div'):\n",
    "        doc.text(sub)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34dffbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_furigana(text):\n",
    "\n",
    "    w_furigana = ''\n",
    "    for pair in split_furigana(text):\n",
    "        if len(pair)==2:\n",
    "            kanji,hira = pair\n",
    "            w_furigana +=  f\"<ruby><rb>{kanji}</rb><rt>{hira}</rt></ruby>\"\n",
    "        else:\n",
    "            w_furigana += pair[0]\n",
    "    return w_furigana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824b64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_html_doc(prj_dir, vid_file, aud_file, sub_file, base_filename, lines_indexed, audio_mode='normal', pad=0.5, line_sep=True):\n",
    "    \"\"\"\n",
    "    audio_mode: normal, off, only\n",
    "    \"\"\" \n",
    "    \n",
    "    prj_name = os.path.basename(prj_dir)\n",
    "    \n",
    "    # 1 Video Found    \n",
    "    if vid_file:\n",
    "        video_capture = cv2.VideoCapture(vid_file)\n",
    "    \n",
    "        if audio_mode == 'normal':\n",
    "            mp_video = mp.VideoFileClip(vid_file)\n",
    "    \n",
    "    # No Video Found\n",
    "    else:\n",
    "        if aud_file:\n",
    "            audio_mode = 'only'\n",
    "            mp_audio = mp.AudioFileClip(aud_file)\n",
    "        \n",
    "\n",
    "    doc, tag, text = Doc().tagtext()\n",
    "    \n",
    "    with tag('html'):\n",
    "        \n",
    "        doc.asis('<style>')\n",
    "        doc.text('div {text-align: center;} .center {display: block; margin-left: auto; margin-right: auto;}')\n",
    "        doc.text('''\n",
    "            body { background-color: #D8DFEE; }\n",
    "            h1, h2, h3 { color: #ABA8A9; }\n",
    "            .highlight { color: #CBF83E; }\n",
    "            div {text-align: center;} \n",
    "            .center {display: block; margin-left: auto; margin-right: auto;}\n",
    "        ''')\n",
    "        doc.asis('</style>')\n",
    "        \n",
    "        with tag('head'):\n",
    "            with tag('title'):\n",
    "                text(prj_name)\n",
    "                \n",
    "            # Image Size Control\n",
    "            with tag('script'):\n",
    "                doc.asis(\"\"\"\n",
    "                function updateImageSize() {\n",
    "                    var slider = document.getElementById(\"slider\");\n",
    "                    var images = document.getElementsByTagName(\"img\");\n",
    "                    for (var i = 0; i < images.length; i++) {\n",
    "                        images[i].style.width = slider.value + \"px\";\n",
    "                        images[i].style.height = \"auto\";\n",
    "                    }\n",
    "                }\n",
    "                \"\"\")\n",
    "        \n",
    "        with tag('body'):\n",
    "            \n",
    "            with doc.tag('div'):\n",
    "                with tag('label', ('for', 'slider')):\n",
    "                    text('Adjust Image Size')\n",
    "                with doc.tag('input', ('type', 'range'), ('min', '50'), ('max', '500'), ('value', '200'), \n",
    "                            ('id', 'slider'), ('oninput', 'updateImageSize()')):\n",
    "                    pass\n",
    "\n",
    "            for idx, r in enumerate(lines_indexed):\n",
    "                line_idx, time_str = r[:2]\n",
    "                sub_list = r[2:]\n",
    "\n",
    "                if ADD_FURIGANA:\n",
    "                    tmp = []\n",
    "                    for s in sub_list:\n",
    "                        try:\n",
    "                            tmp += [add_furigana(s)]\n",
    "                        except:\n",
    "                            tmp += [s]\n",
    "\n",
    "                    sub_list = tmp\n",
    "\n",
    "                start, stop = srt_time_to_seconds(time_str)\n",
    "                time_ms = int(1000*((stop - start)/2 + start))\n",
    "                \n",
    "                # Process Video-------------------\n",
    "                if audio_mode != 'only':\n",
    "                    video_capture.set(cv2.CAP_PROP_POS_MSEC, time_ms)\n",
    "                    success, image = video_capture.read()\n",
    "\n",
    "                    if success:\n",
    "                        new_filename = prj_name + '_' + str(time_ms) + '.jpg'\n",
    "                        path = os.path.join(prj_dir, new_filename)\n",
    "                        if not(os.path.exists(path)):\n",
    "                            cv2.imwrite(path, image)\n",
    "                            \n",
    "                        h, w = image.shape[:-1]\n",
    "                        ratio = h/w\n",
    "                        \n",
    "                        add_image(doc, new_filename, idx, w=WIDTH, h=int(WIDTH*ratio))\n",
    "                \n",
    "                # Add Subtitle---------------------\n",
    "                for s in sub_list:\n",
    "                    add_sub(doc, s)\n",
    "                            \n",
    "                # Process Audio--------------------\n",
    "                if audio_mode != 'off':                    \n",
    "                    new_filename = prj_name + '_' + str(time_ms) + '.mp3'\n",
    "                    path = os.path.join(prj_dir, new_filename)\n",
    "                    \n",
    "                    # Audio Only Mode\n",
    "                    if audio_mode == 'only':\n",
    "                        # Get audio subclip from audio file\n",
    "                        mp_audio.subclip(max(0, start - pad), stop+pad).write_audiofile(path, verbose=False, logger=None)\n",
    "                        \n",
    "                    # Normal Audio Mode\n",
    "                    else:\n",
    "                        # Get audio subclip from video file\n",
    "                        mp_video.subclip(max(0, start - pad), stop+pad).audio.write_audiofile(path, verbose=False, logger=None)\n",
    "                    \n",
    "                    add_audio_clip(doc, path)\n",
    "                    \n",
    "                if line_sep:\n",
    "                    doc.stag('hr')  # Add a horizontal line\n",
    "            \n",
    "    return doc.indent(doc.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c938f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = whisper.torch.device('cuda' if whisper.torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2bc3042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an mp3 from video file\n",
    "def extract_audio(vid_file, track_number=0): \n",
    "    def extract_ffmpeg(input_file, output_file, audio_track):\n",
    "        command = f'ffmpeg -i \"{input_file}\" -map 0:a:{audio_track} \"{output_file}\"'\n",
    "        result = subprocess.run(command, shell=True, text=True, capture_output=True)\n",
    "        print(\"stdout:\", result.stdout)\n",
    "        print(\"stderr:\", result.stderr)\n",
    "        \n",
    "    base_filename = os.path.splitext(vid_file)[0] # Remove ext\n",
    "\n",
    "    savename = base_filename + '.mp3'\n",
    "\n",
    "    # Default to using MoviePy\n",
    "    if track_number == 0:\n",
    "        v = mp.VideoFileClip(f)\n",
    "        v.audio.write_audiofile(savename)\n",
    "        \n",
    "    # Extract different track, need ffmpeg\n",
    "    else:\n",
    "        try:\n",
    "            extract_ffmpeg(vid_file, savename, track_number)\n",
    "        except Exception as e:\n",
    "            #print('Cant process ffmpeg. Ensure you have ffmpeg installed.')\n",
    "            print(f'FFMPEG Error: {e}')\n",
    "            \n",
    "    return savename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43cf0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(transcription, base_filename):\n",
    "    savepath = base_filename + '.srt'\n",
    "    segments = transcription['segments']\n",
    "\n",
    "    for segment in segments:\n",
    "        startTime = str(0)+str(timedelta(seconds=int(segment['start'])))+',000'\n",
    "        endTime = str(0)+str(timedelta(seconds=int(segment['end'])))+',000'\n",
    "        text = segment['text']\n",
    "        if len(text) == 0:\n",
    "            continue\n",
    "        \n",
    "        segmentId = segment['id']+1\n",
    "        segment = f\"{segmentId}\\n{startTime} --> {endTime}\\n{text[1:] if text[0] is ' ' else text}\\n\\n\"\n",
    "\n",
    "        with open(savepath, 'a', encoding='utf-8') as srtFile:\n",
    "            srtFile.write(segment)\n",
    "            \n",
    "    return savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fc83738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prj_media(base_filename):\n",
    "    has_ext = lambda exts: [f for f in files if f.startswith(base_filename) and os.path.splitext(f)[-1].lower() in exts]\n",
    "    \n",
    "    vid_files = has_ext(VID_EXTS)\n",
    "    aud_files = has_ext(AUD_EXTS)\n",
    "    sub_files = has_ext(SUB_EXTS)\n",
    "    \n",
    "    assert len(vid_files) <= 1, \"Multiple video extensions found w/ same base name.\"\n",
    "    assert len(aud_files) <= 1, \"Multiple audio extensions found w/ same base name.\"\n",
    "    \n",
    "    # 1 Video Found    \n",
    "    vid_file = vid_files[0] if len(vid_files) == 1 else None\n",
    "    aud_file = aud_files[0] if len(aud_files) == 1 else None\n",
    "    sub_file = sub_files[0] if len(sub_files) == 1 else None\n",
    "    \n",
    "    return vid_file, aud_file, sub_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4401bcab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: None, Input\\2023年6月10日（土）「OK! Cozy up!週末増刊号」.mp3, None\n",
      "Creating transcript using OpenAIs Whisper for Input\\2023年6月10日（土）「OK! Cozy up!週末増刊号」.mp3.\n",
      "Exporting subtitle.\n",
      "Sub File Extracted: Input\\2023年6月10日（土）「OK! Cozy up!週末増刊号」.srt\n",
      "Generating Audio Visual HTML Page\n",
      "Finished processing Input\\2023年6月10日（土）「OK! Cozy up!週末増刊号」\n",
      "Total processing time: 435.4954299926758\n"
     ]
    }
   ],
   "source": [
    "TRACK_NUMBER = 2\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for prj in proj_files:    \n",
    "    vid_file, aud_file, sub_file = get_prj_media(prj)\n",
    "    print(f'Files: {vid_file}, {aud_file}, {sub_file}')\n",
    "    \n",
    "    # if audio doesnt exist extract it from video\n",
    "    if aud_file == None:\n",
    "        if vid_file:\n",
    "            print(f'Extracting mp3 from {prj}...')\n",
    "            aud_file = extract_audio(vid_file, track_number=TRACK_NUMBER)\n",
    "            print(f'Audio File Extracted: {aud_file}')\n",
    "            print('Finished extracting audio.')\n",
    "    \n",
    "    # Use subtitle file doesn't exists create it\n",
    "    if sub_file == None:\n",
    "        if os.path.exists(aud_file):\n",
    "            print(f'Creating transcript using OpenAIs Whisper for {aud_file}.')\n",
    "            \n",
    "            model = whisper.load_model(\"base\")\n",
    "            transcription = model.transcribe(aud_file)\n",
    "            \n",
    "            print('Exporting subtitle.')\n",
    "            sub_file = transcribe_audio(transcription, prj)\n",
    "            print(f'Sub File Extracted: {sub_file}')\n",
    "        else:\n",
    "            print(f'Error. Audio file {aud_file} not found.')\n",
    "        \n",
    "    # Check if subtitle exists\n",
    "    if os.path.exists(sub_file):\n",
    "        print('Generating Audio Visual HTML Page')\n",
    "        \n",
    "        prj_name = os.path.basename(prj).replace(' ','_')\n",
    "        prj_dir = os.path.join(out_dir, prj_name)\n",
    "        if not(os.path.exists(prj_dir)):\n",
    "            os.mkdir(prj_dir)\n",
    "\n",
    "        line_list = file_to_line_list(sub_file)\n",
    "        lines_indexed = chunk_sub_idx_to_list(line_list)\n",
    "\n",
    "        html = build_html_doc(prj_dir, vid_file, aud_file, sub_file, prj, lines_indexed)\n",
    "\n",
    "        save_path = os.path.join(prj_dir, prj_name + '.html')\n",
    "        \n",
    "        with open(save_path, 'w', encoding='utf-8') as html_file:\n",
    "            html_file.write(html)\n",
    "\n",
    "        print(f'Finished processing {prj}')\n",
    "\n",
    "    else:\n",
    "        print(f'Error. Subtitle file {sub_file} not found.')\n",
    "\n",
    "minutes = round((time.time() - start_time)/60, 2)\n",
    "print(f'Total processing time: {minutes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee432f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d787b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Input\\\\2023年6月10日（土）「OK! Cozy up!週末増刊号」.mp3'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afde16cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: ja\n"
     ]
    }
   ],
   "source": [
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(aud_file)\n",
    "sample = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(sample).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3769d521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ja'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(probs, key=probs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfb40f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pad_or_trim in module whisper.audio:\n",
      "\n",
      "pad_or_trim(array, length: int = 480000, *, axis: int = -1)\n",
      "    Pad or trim the audio array to N_SAMPLES, as expected by the encoder.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(whisper.pad_or_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d875449",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\", device=device)\n",
    "audio = whisper.load_audio(aud_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "809f76e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\whisper\\transcribe.py:229\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[0;32m    226\u001b[0m mel_segment \u001b[38;5;241m=\u001b[39m pad_or_trim(mel_segment, N_FRAMES)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[0;32m    228\u001b[0m decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[1;32m--> 229\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\whisper\\transcribe.py:164\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[1;34m(segment)\u001b[0m\n\u001b[0;32m    161\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m options \u001b[38;5;241m=\u001b[39m DecodingOptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, temperature\u001b[38;5;241m=\u001b[39mt)\n\u001b[1;32m--> 164\u001b[0m decode_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m needs_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    168\u001b[0m     compression_ratio_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m decode_result\u001b[38;5;241m.\u001b[39mcompression_ratio \u001b[38;5;241m>\u001b[39m compression_ratio_threshold\n\u001b[0;32m    170\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\whisper\\decoding.py:811\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    809\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 811\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\whisper\\decoding.py:724\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[1;34m(self, mel)\u001b[0m\n\u001b[0;32m    721\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(audio_features\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    723\u001b[0m \u001b[38;5;66;03m# call the main sampling loop\u001b[39;00m\n\u001b[1;32m--> 724\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[0;32m    727\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m audio_features[:: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\whisper\\decoding.py:686\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[1;34m(self, audio_features, tokens)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;66;03m# apply the logit filters, e.g. for suppressing or applying penalty to\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logit_filter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogit_filters:\n\u001b[1;32m--> 686\u001b[0m     \u001b[43mlogit_filter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;66;03m# expand the tokens tensor with the selected next tokens\u001b[39;00m\n\u001b[0;32m    689\u001b[0m tokens, completed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mupdate(tokens, logits, sum_logprobs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\whisper\\decoding.py:453\u001b[0m, in \u001b[0;36mApplyTimestampRules.apply\u001b[1;34m(self, logits, tokens)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    452\u001b[0m     sampled_tokens \u001b[38;5;241m=\u001b[39m tokens[k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_begin :]\n\u001b[1;32m--> 453\u001b[0m     seq \u001b[38;5;241m=\u001b[39m [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[43msampled_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m    454\u001b[0m     last_was_timestamp \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    455\u001b[0m         \u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m seq[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mtimestamp_begin\n\u001b[0;32m    456\u001b[0m     )\n\u001b[0;32m    457\u001b[0m     penultimate_was_timestamp \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m seq[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mtimestamp_begin\n\u001b[0;32m    459\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = model.transcribe(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da1d9572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '6月10日土曜日日本放送OK 工事イヤップ 週末増換号日本放送はナンサーの新用一家ですOK 工事イヤップ 週末増換号今週の放送でセレクトした聞き所今後のニュースの予定を紹介していくプログラムです',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 6.0,\n",
       "   'text': '6月10日土曜日',\n",
       "   'tokens': [50364, 21, 6939, 3279, 6890, 45506, 9531, 250, 6890, 50664],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4274945772611178,\n",
       "   'compression_ratio': 1.2881355932203389,\n",
       "   'no_speech_prob': 0.4644383490085602},\n",
       "  {'id': 1,\n",
       "   'seek': 0,\n",
       "   'start': 6.0,\n",
       "   'end': 12.0,\n",
       "   'text': '日本放送OK 工事イヤップ 週末増換号',\n",
       "   'tokens': [50664,\n",
       "    27311,\n",
       "    12744,\n",
       "    29309,\n",
       "    9443,\n",
       "    220,\n",
       "    23323,\n",
       "    6973,\n",
       "    8040,\n",
       "    34969,\n",
       "    33683,\n",
       "    220,\n",
       "    38003,\n",
       "    1474,\n",
       "    104,\n",
       "    24228,\n",
       "    245,\n",
       "    36338,\n",
       "    26987,\n",
       "    50964],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4274945772611178,\n",
       "   'compression_ratio': 1.2881355932203389,\n",
       "   'no_speech_prob': 0.4644383490085602},\n",
       "  {'id': 2,\n",
       "   'seek': 0,\n",
       "   'start': 17.0,\n",
       "   'end': 20.0,\n",
       "   'text': '日本放送はナンサーの新用一家です',\n",
       "   'tokens': [51214,\n",
       "    27311,\n",
       "    12744,\n",
       "    29309,\n",
       "    3065,\n",
       "    26719,\n",
       "    4824,\n",
       "    23607,\n",
       "    3384,\n",
       "    2972,\n",
       "    12560,\n",
       "    9254,\n",
       "    2257,\n",
       "    5155,\n",
       "    4767,\n",
       "    51364],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4274945772611178,\n",
       "   'compression_ratio': 1.2881355932203389,\n",
       "   'no_speech_prob': 0.4644383490085602},\n",
       "  {'id': 3,\n",
       "   'seek': 0,\n",
       "   'start': 20.0,\n",
       "   'end': 24.0,\n",
       "   'text': 'OK 工事イヤップ 週末増換号',\n",
       "   'tokens': [51364,\n",
       "    9443,\n",
       "    220,\n",
       "    23323,\n",
       "    6973,\n",
       "    8040,\n",
       "    34969,\n",
       "    33683,\n",
       "    220,\n",
       "    38003,\n",
       "    1474,\n",
       "    104,\n",
       "    24228,\n",
       "    245,\n",
       "    36338,\n",
       "    26987,\n",
       "    51564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4274945772611178,\n",
       "   'compression_ratio': 1.2881355932203389,\n",
       "   'no_speech_prob': 0.4644383490085602},\n",
       "  {'id': 4,\n",
       "   'seek': 2400,\n",
       "   'start': 24.0,\n",
       "   'end': 27.0,\n",
       "   'text': '今週の放送でセレクトした聞き所',\n",
       "   'tokens': [50364,\n",
       "    6480,\n",
       "    38003,\n",
       "    2972,\n",
       "    12744,\n",
       "    29309,\n",
       "    2474,\n",
       "    31223,\n",
       "    16680,\n",
       "    10825,\n",
       "    7588,\n",
       "    8533,\n",
       "    25468,\n",
       "    7016,\n",
       "    5966,\n",
       "    50514],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1623497939691311,\n",
       "   'compression_ratio': 1.054054054054054,\n",
       "   'no_speech_prob': 0.4819837212562561},\n",
       "  {'id': 5,\n",
       "   'seek': 2400,\n",
       "   'start': 27.0,\n",
       "   'end': 30.0,\n",
       "   'text': '今後のニュースの予定を紹介していくプログラムです',\n",
       "   'tokens': [50514,\n",
       "    6480,\n",
       "    5661,\n",
       "    2972,\n",
       "    34737,\n",
       "    26167,\n",
       "    3384,\n",
       "    9550,\n",
       "    2972,\n",
       "    1369,\n",
       "    230,\n",
       "    12088,\n",
       "    5998,\n",
       "    38193,\n",
       "    30312,\n",
       "    8822,\n",
       "    49394,\n",
       "    20953,\n",
       "    17164,\n",
       "    23839,\n",
       "    11353,\n",
       "    32026,\n",
       "    4767,\n",
       "    50664],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1623497939691311,\n",
       "   'compression_ratio': 1.054054054054054,\n",
       "   'no_speech_prob': 0.4819837212562561}],\n",
       " 'language': 'ja'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89036171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
