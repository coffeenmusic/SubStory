{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a7157f0",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- Fix adding furigana. Doesnt seem to be\n",
    "- Allow resolution change to saved images to save space.\n",
    "- Pass language to Whisper???\n",
    "- Change from Whisper to Facebook's fairseq MMC? https://github.com/facebookresearch/fairseq/tree/main/examples/mms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f2aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steph\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Steph\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\whisper\\timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import whisper\n",
    "import torch\n",
    "import moviepy.editor as mp\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import subprocess\n",
    "from datetime import timedelta\n",
    "from yattag import Doc\n",
    "import time\n",
    "\n",
    "\n",
    "ADD_FURIGANA = True\n",
    "VID_EXTS = ['.mp4','.avi','.ogv','.mkv','.webm']\n",
    "AUD_EXTS = ['.mp3']\n",
    "SUB_EXTS = ['.srt']\n",
    "WIDTH = 200\n",
    "src_dir = 'Input'\n",
    "out_dir = 'Output'\n",
    "files = [os.path.join(src_dir, f) for f in os.listdir(src_dir)]\n",
    "\n",
    "if ADD_FURIGANA:\n",
    "    from furigana.furigana import split_furigana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f8b0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Input\\\\2023年6月10日（土）「OK! Cozy up!週末増刊号」']\n"
     ]
    }
   ],
   "source": [
    "proj_files = [os.path.splitext(f)[0] for f in files if os.path.splitext(f)[-1] in VID_EXTS]\n",
    "\n",
    "# Add audio files if they weren't extracted from a video with the same name\n",
    "proj_files += [os.path.splitext(f)[0] for f in files if os.path.splitext(f)[-1] in AUD_EXTS and os.path.splitext(f)[0] not in proj_files]\n",
    "print(proj_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30b6082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_line_list(filename, encoding='utf-8-sig'):\n",
    "        line_list = []\n",
    "        with open(filename, 'r', encoding=encoding) as file:\n",
    "            for line in file:\n",
    "                line_list += [line.replace('\\n', '')]\n",
    "        return line_list\n",
    "\n",
    "def chunk_sub_idx_to_list(sub_line_list):\n",
    "        \"\"\"\n",
    "            Pass in a list where each line is a line in the subtitle file\n",
    "            Example:\n",
    "            ['1', '00:00:00,000 --> 00:00:04,430', 'おはようございます', '2', ...]\n",
    "\n",
    "            return a list where each list item is another list where each item is specific to its index\n",
    "            Example:\n",
    "            [['1', '00:00:00,000 --> 00:00:04,430', 'おはようございます'], ['2', ...], ...]\n",
    "        \"\"\"\n",
    "        lines_indexed = []\n",
    "        tmp = []\n",
    "        for i, line in enumerate(sub_line_list):\n",
    "            if line == '':\n",
    "                continue\n",
    "\n",
    "            tmp += [line]\n",
    "            if len(tmp) > 3:\n",
    "                digit, timestamp = tmp[-2:]\n",
    "                if digit.strip().isdigit() and '-->' in timestamp:\n",
    "                    lines_indexed += [tmp[:-2]]\n",
    "                    tmp = tmp[-2:]\n",
    "        return lines_indexed\n",
    "    \n",
    "def srt_time_to_seconds(time_line):\n",
    "    def timestr_to_sec(time_str):\n",
    "        h, m, s_str = time_str.split(':')\n",
    "        s, ms = s_str.split(',')\n",
    "        return int(h)*60*60 + int(m)*60 + int(s) + int(ms)/1000 \n",
    "\n",
    "    start_time_str, stop_time_str = time_line.split(' --> ')\n",
    "    start_time = timestr_to_sec(start_time_str)\n",
    "    stop_time = timestr_to_sec(stop_time_str)\n",
    "\n",
    "    return start_time, stop_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a33025bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image(doc, image, idx, w=200, h=200):\n",
    "    basename = os.path.splitext(os.path.basename(image))[0]\n",
    "    with doc.tag('img', id=f'image_{idx}', src=image, alt=basename, width=w, height=h, klass=\"center\"):\n",
    "        pass # No content within this tag\n",
    "\n",
    "def add_audio_clip(doc, audio_file, idx):\n",
    "    with doc.tag('audio', controls=True, klass=\"center\"):\n",
    "        doc.stag('source', src=os.path.basename(audio_file), type=\"audio/mpeg\")\n",
    "        doc.text('Your browser does not support the audio element.')\n",
    "\n",
    "def add_sub(doc, sub):\n",
    "    with doc.tag('div'):\n",
    "        doc.text(sub)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34dffbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_furigana(text):\n",
    "\n",
    "    w_furigana = ''\n",
    "    for pair in split_furigana(text):\n",
    "        if len(pair)==2:\n",
    "            kanji,hira = pair\n",
    "            w_furigana +=  f\"<ruby><rb>{kanji}</rb><rt>{hira}</rt></ruby>\"\n",
    "        else:\n",
    "            w_furigana += pair[0]\n",
    "    return w_furigana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "727aaa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_html_doc(prj_dir, vid_file, aud_file, sub_file, base_filename, lines_indexed, audio_mode='normal', pad=0.5, line_sep=True):\n",
    "    \"\"\"\n",
    "    audio_mode: normal, off, only\n",
    "    \"\"\" \n",
    "    \n",
    "    prj_name = os.path.basename(prj_dir)\n",
    "    \n",
    "    # 1 Video Found    \n",
    "    if vid_file:\n",
    "        video_capture = cv2.VideoCapture(vid_file)\n",
    "    \n",
    "        if audio_mode == 'normal':\n",
    "            mp_video = mp.VideoFileClip(vid_file)\n",
    "    \n",
    "    # No Video Found\n",
    "    else:\n",
    "        if aud_file:\n",
    "            audio_mode = 'only'\n",
    "            mp_audio = mp.AudioFileClip(aud_file)\n",
    "        \n",
    "\n",
    "    doc, tag, text = Doc().tagtext()\n",
    "    \n",
    "    with tag('html'):\n",
    "        \n",
    "        doc.asis('<style>')\n",
    "        doc.text('div {text-align: center;} .center {display: block; margin-left: auto; margin-right: auto;}')\n",
    "        doc.text('''\n",
    "            body { background-color: #D8DFEE; }\n",
    "            h1, h2, h3 { color: #ABA8A9; }\n",
    "            .highlight { color: #CBF83E; }\n",
    "            div {text-align: center;} \n",
    "            .center {display: block; margin-left: auto; margin-right: auto;}\n",
    "        ''')\n",
    "        doc.asis('</style>')\n",
    "        \n",
    "        with tag('head'):\n",
    "            with tag('title'):\n",
    "                text(prj_name)\n",
    "                \n",
    "            # Image Size Control\n",
    "            with tag('script'):\n",
    "                doc.asis(\"\"\"\n",
    "                function updateImageSize() {\n",
    "                    var slider = document.getElementById(\"slider\");\n",
    "                    var images = document.getElementsByTagName(\"img\");\n",
    "                    for (var i = 0; i < images.length; i++) {\n",
    "                        images[i].style.width = slider.value + \"px\";\n",
    "                        images[i].style.height = \"auto\";\n",
    "                    }\n",
    "                }\n",
    "                \"\"\")\n",
    "        \n",
    "        with tag('body'):\n",
    "            \n",
    "            with doc.tag('div'):\n",
    "                with tag('label', ('for', 'slider')):\n",
    "                    text('Adjust Image Size')\n",
    "                with doc.tag('input', ('type', 'range'), ('min', '50'), ('max', '500'), ('value', '200'), \n",
    "                            ('id', 'slider'), ('oninput', 'updateImageSize()')):\n",
    "                    pass\n",
    "\n",
    "            for idx, r in enumerate(lines_indexed):\n",
    "                line_idx, time_str = r[:2]\n",
    "                sub_list = r[2:]\n",
    "\n",
    "                if ADD_FURIGANA:\n",
    "                    tmp = []\n",
    "                    for s in sub_list:\n",
    "                        try:\n",
    "                            tmp += [add_furigana(s)]\n",
    "                        except:\n",
    "                            tmp += [s]\n",
    "\n",
    "                    sub_list = tmp\n",
    "\n",
    "                start, stop = srt_time_to_seconds(time_str)\n",
    "                time_ms = int(1000*((stop - start)/2 + start))\n",
    "                \n",
    "                # Process Video-------------------\n",
    "                if audio_mode != 'only':\n",
    "                    video_capture.set(cv2.CAP_PROP_POS_MSEC, time_ms)\n",
    "                    success, image = video_capture.read()\n",
    "\n",
    "                    if success:\n",
    "                        new_filename = prj_name + '_' + str(time_ms) + '.jpg'\n",
    "                        path = os.path.join(prj_dir, new_filename)\n",
    "                        if not(os.path.exists(path)):\n",
    "                            cv2.imwrite(path, image)\n",
    "                            \n",
    "                        h, w = image.shape[:-1]\n",
    "                        ratio = h/w\n",
    "                        \n",
    "                        add_image(doc, new_filename, idx, w=WIDTH, h=int(WIDTH*ratio))\n",
    "                \n",
    "                # Add Subtitle---------------------\n",
    "                for s in sub_list:\n",
    "                    add_sub(doc, s)\n",
    "                            \n",
    "                # Process Audio--------------------\n",
    "                if audio_mode != 'off':                    \n",
    "                    new_filename = prj_name + '_' + str(time_ms) + '.mp3'\n",
    "                    path = os.path.join(prj_dir, new_filename)\n",
    "                    \n",
    "                    # Audio Only Mode\n",
    "                    if audio_mode == 'only':\n",
    "                        # Get audio subclip from audio file\n",
    "                        mp_audio.subclip(max(0, start - pad), stop+pad).write_audiofile(path, verbose=False, logger=None)\n",
    "                        \n",
    "                    # Normal Audio Mode\n",
    "                    else:\n",
    "                        # Get audio subclip from video file\n",
    "                        mp_video.subclip(max(0, start - pad), stop+pad).audio.write_audiofile(path, verbose=False, logger=None)\n",
    "                    \n",
    "                    add_audio_clip(doc, path)\n",
    "                    \n",
    "                if line_sep:\n",
    "                    doc.stag('hr')  # Add a horizontal line\n",
    "            \n",
    "    return doc.indent(doc.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f2cb43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = whisper.torch.device('cuda' if whisper.torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c873dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an mp3 from video file\n",
    "def extract_audio(vid_file, track_number=0): \n",
    "    def extract_ffmpeg(input_file, output_file, audio_track):\n",
    "        command = f'ffmpeg -i \"{input_file}\" -map 0:a:{audio_track} \"{output_file}\"'\n",
    "        result = subprocess.run(command, shell=True, text=True, capture_output=True)\n",
    "        print(\"stdout:\", result.stdout)\n",
    "        print(\"stderr:\", result.stderr)\n",
    "        \n",
    "    base_filename = os.path.splitext(vid_file)[0] # Remove ext\n",
    "\n",
    "    savename = base_filename + '.mp3'\n",
    "\n",
    "    # Default to using MoviePy\n",
    "    if track_number == 0:\n",
    "        v = mp.VideoFileClip(f)\n",
    "        v.audio.write_audiofile(savename)\n",
    "        \n",
    "    # Extract different track, need ffmpeg\n",
    "    else:\n",
    "        try:\n",
    "            extract_ffmpeg(vid_file, savename, track_number)\n",
    "        except Exception as e:\n",
    "            #print('Cant process ffmpeg. Ensure you have ffmpeg installed.')\n",
    "            print(f'FFMPEG Error: {e}')\n",
    "            \n",
    "    return savename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "199bb163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(transcription, base_filename):\n",
    "    savepath = base_filename + '.srt'\n",
    "    segments = transcription['segments']\n",
    "\n",
    "    for segment in segments:\n",
    "        startTime = str(0)+str(timedelta(seconds=int(segment['start'])))+',000'\n",
    "        endTime = str(0)+str(timedelta(seconds=int(segment['end'])))+',000'\n",
    "        text = segment['text']\n",
    "        if len(text) == 0:\n",
    "            continue\n",
    "        \n",
    "        segmentId = segment['id']+1\n",
    "        segment = f\"{segmentId}\\n{startTime} --> {endTime}\\n{text[1:] if text[0] is ' ' else text}\\n\\n\"\n",
    "\n",
    "        with open(savepath, 'a', encoding='utf-8') as srtFile:\n",
    "            srtFile.write(segment)\n",
    "            \n",
    "    return savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb3bf48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prj_media(base_filename):\n",
    "    has_ext = lambda exts: [f for f in files if f.startswith(base_filename) and os.path.splitext(f)[-1].lower() in exts]\n",
    "    \n",
    "    vid_files = has_ext(VID_EXTS)\n",
    "    aud_files = has_ext(AUD_EXTS)\n",
    "    sub_files = has_ext(SUB_EXTS)\n",
    "    \n",
    "    assert len(vid_files) <= 1, \"Multiple video extensions found w/ same base name.\"\n",
    "    assert len(aud_files) <= 1, \"Multiple audio extensions found w/ same base name.\"\n",
    "    \n",
    "    # 1 Video Found    \n",
    "    vid_file = vid_files[0] if len(vid_files) == 1 else None\n",
    "    aud_file = aud_files[0] if len(aud_files) == 1 else None\n",
    "    sub_file = sub_files[0] if len(sub_files) == 1 else None\n",
    "    \n",
    "    return vid_file, aud_file, sub_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56d9febc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: None, Input\\2023年6月10日（土）「OK! Cozy up!週末増刊号」.mp3, None\n",
      "Creating transcript using OpenAIs Whisper for Input\\2023年6月10日（土）「OK! Cozy up!週末増刊号」.mp3.\n",
      "Exporting subtitle.\n",
      "Sub File Extracted: Input\\2023年6月10日（土）「OK! Cozy up!週末増刊号」.srt\n",
      "Generating Audio Visual HTML Page\n",
      "Finished processing Input\\2023年6月10日（土）「OK! Cozy up!週末増刊号」\n",
      "Total processing time: 435.4954299926758\n"
     ]
    }
   ],
   "source": [
    "TRACK_NUMBER = 2\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for prj in proj_files:    \n",
    "    vid_file, aud_file, sub_file = get_prj_media(prj)\n",
    "    print(f'Files: {vid_file}, {aud_file}, {sub_file}')\n",
    "    \n",
    "    # if audio doesnt exist extract it from video\n",
    "    if aud_file == None:\n",
    "        if vid_file:\n",
    "            print(f'Extracting mp3 from {prj}...')\n",
    "            aud_file = extract_audio(vid_file, track_number=TRACK_NUMBER)\n",
    "            print(f'Audio File Extracted: {aud_file}')\n",
    "            print('Finished extracting audio.')\n",
    "    \n",
    "    # Use subtitle file doesn't exists create it\n",
    "    if sub_file == None:\n",
    "        if os.path.exists(aud_file):\n",
    "            print(f'Creating transcript using OpenAIs Whisper for {aud_file}.')\n",
    "            \n",
    "            model = whisper.load_model(\"base\")\n",
    "            transcription = model.transcribe(aud_file)\n",
    "            \n",
    "            print('Exporting subtitle.')\n",
    "            sub_file = transcribe_audio(transcription, prj)\n",
    "            print(f'Sub File Extracted: {sub_file}')\n",
    "        else:\n",
    "            print(f'Error. Audio file {aud_file} not found.')\n",
    "        \n",
    "    # Check if subtitle exists\n",
    "    if os.path.exists(sub_file):\n",
    "        print('Generating Audio Visual HTML Page')\n",
    "        \n",
    "        prj_name = os.path.basename(prj).replace(' ','_')\n",
    "        prj_dir = os.path.join(out_dir, prj_name)\n",
    "        if not(os.path.exists(prj_dir)):\n",
    "            os.mkdir(prj_dir)\n",
    "\n",
    "        line_list = file_to_line_list(sub_file)\n",
    "        lines_indexed = chunk_sub_idx_to_list(line_list)\n",
    "\n",
    "        html = build_html_doc(prj_dir, vid_file, aud_file, sub_file, prj, lines_indexed)\n",
    "\n",
    "        save_path = os.path.join(prj_dir, prj_name + '.html')\n",
    "        \n",
    "        with open(save_path, 'w', encoding='utf-8') as html_file:\n",
    "            html_file.write(html)\n",
    "\n",
    "        print(f'Finished processing {prj}')\n",
    "\n",
    "    else:\n",
    "        print(f'Error. Subtitle file {sub_file} not found.')\n",
    "\n",
    "minutes = round((time.time() - start_time)/60, 2)\n",
    "print(f'Total processing time: {minutes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdec493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5368f31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Input\\\\2023年6月10日（土）「OK! Cozy up!週末増刊号」.mp3'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b033259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: ja\n"
     ]
    }
   ],
   "source": [
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(aud_file)\n",
    "sample = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(sample).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9ac6d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ja'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(probs, key=probs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c404d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pad_or_trim in module whisper.audio:\n",
      "\n",
      "pad_or_trim(array, length: int = 480000, *, axis: int = -1)\n",
      "    Pad or trim the audio array to N_SAMPLES, as expected by the encoder.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(whisper.pad_or_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5899ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\", device=device)\n",
    "audio = whisper.load_audio(aud_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3001cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "592875b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.transcribe(sample, language=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70483364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '6月10日土曜日日本放送OK 工事イヤップ 週末増換号日本放送はナンサーの新用一家ですOK 工事イヤップ 週末増換号今週の放送でセレクトした聞き所今後のニュースの予定を紹介していくプログラムです',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 6.0,\n",
       "   'text': '6月10日土曜日',\n",
       "   'tokens': [50364, 21, 6939, 3279, 6890, 45506, 9531, 250, 6890, 50664],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4274945772611178,\n",
       "   'compression_ratio': 1.2881355932203389,\n",
       "   'no_speech_prob': 0.4644383490085602},\n",
       "  {'id': 1,\n",
       "   'seek': 0,\n",
       "   'start': 6.0,\n",
       "   'end': 12.0,\n",
       "   'text': '日本放送OK 工事イヤップ 週末増換号',\n",
       "   'tokens': [50664,\n",
       "    27311,\n",
       "    12744,\n",
       "    29309,\n",
       "    9443,\n",
       "    220,\n",
       "    23323,\n",
       "    6973,\n",
       "    8040,\n",
       "    34969,\n",
       "    33683,\n",
       "    220,\n",
       "    38003,\n",
       "    1474,\n",
       "    104,\n",
       "    24228,\n",
       "    245,\n",
       "    36338,\n",
       "    26987,\n",
       "    50964],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4274945772611178,\n",
       "   'compression_ratio': 1.2881355932203389,\n",
       "   'no_speech_prob': 0.4644383490085602},\n",
       "  {'id': 2,\n",
       "   'seek': 0,\n",
       "   'start': 17.0,\n",
       "   'end': 20.0,\n",
       "   'text': '日本放送はナンサーの新用一家です',\n",
       "   'tokens': [51214,\n",
       "    27311,\n",
       "    12744,\n",
       "    29309,\n",
       "    3065,\n",
       "    26719,\n",
       "    4824,\n",
       "    23607,\n",
       "    3384,\n",
       "    2972,\n",
       "    12560,\n",
       "    9254,\n",
       "    2257,\n",
       "    5155,\n",
       "    4767,\n",
       "    51364],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4274945772611178,\n",
       "   'compression_ratio': 1.2881355932203389,\n",
       "   'no_speech_prob': 0.4644383490085602},\n",
       "  {'id': 3,\n",
       "   'seek': 0,\n",
       "   'start': 20.0,\n",
       "   'end': 24.0,\n",
       "   'text': 'OK 工事イヤップ 週末増換号',\n",
       "   'tokens': [51364,\n",
       "    9443,\n",
       "    220,\n",
       "    23323,\n",
       "    6973,\n",
       "    8040,\n",
       "    34969,\n",
       "    33683,\n",
       "    220,\n",
       "    38003,\n",
       "    1474,\n",
       "    104,\n",
       "    24228,\n",
       "    245,\n",
       "    36338,\n",
       "    26987,\n",
       "    51564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4274945772611178,\n",
       "   'compression_ratio': 1.2881355932203389,\n",
       "   'no_speech_prob': 0.4644383490085602},\n",
       "  {'id': 4,\n",
       "   'seek': 2400,\n",
       "   'start': 24.0,\n",
       "   'end': 27.0,\n",
       "   'text': '今週の放送でセレクトした聞き所',\n",
       "   'tokens': [50364,\n",
       "    6480,\n",
       "    38003,\n",
       "    2972,\n",
       "    12744,\n",
       "    29309,\n",
       "    2474,\n",
       "    31223,\n",
       "    16680,\n",
       "    10825,\n",
       "    7588,\n",
       "    8533,\n",
       "    25468,\n",
       "    7016,\n",
       "    5966,\n",
       "    50514],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1623497939691311,\n",
       "   'compression_ratio': 1.054054054054054,\n",
       "   'no_speech_prob': 0.4819837212562561},\n",
       "  {'id': 5,\n",
       "   'seek': 2400,\n",
       "   'start': 27.0,\n",
       "   'end': 30.0,\n",
       "   'text': '今後のニュースの予定を紹介していくプログラムです',\n",
       "   'tokens': [50514,\n",
       "    6480,\n",
       "    5661,\n",
       "    2972,\n",
       "    34737,\n",
       "    26167,\n",
       "    3384,\n",
       "    9550,\n",
       "    2972,\n",
       "    1369,\n",
       "    230,\n",
       "    12088,\n",
       "    5998,\n",
       "    38193,\n",
       "    30312,\n",
       "    8822,\n",
       "    49394,\n",
       "    20953,\n",
       "    17164,\n",
       "    23839,\n",
       "    11353,\n",
       "    32026,\n",
       "    4767,\n",
       "    50664],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1623497939691311,\n",
       "   'compression_ratio': 1.054054054054054,\n",
       "   'no_speech_prob': 0.4819837212562561}],\n",
       " 'language': 'ja'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ab7758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method transcribe in module whisper.transcribe:\n",
      "\n",
      "transcribe(audio: Union[str, numpy.ndarray, torch.Tensor], *, verbose: Optional[bool] = None, temperature: Union[float, Tuple[float, ...]] = (0.0, 0.2, 0.4, 0.6, 0.8, 1.0), compression_ratio_threshold: Optional[float] = 2.4, logprob_threshold: Optional[float] = -1.0, no_speech_threshold: Optional[float] = 0.6, condition_on_previous_text: bool = True, initial_prompt: Optional[str] = None, word_timestamps: bool = False, prepend_punctuations: str = '\"\\'“¿([{-', append_punctuations: str = '\"\\'.。,，!！?？:：”)]}、', **decode_options) method of whisper.model.Whisper instance\n",
      "    Transcribe an audio file using Whisper\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    model: Whisper\n",
      "        The Whisper model instance\n",
      "    \n",
      "    audio: Union[str, np.ndarray, torch.Tensor]\n",
      "        The path to the audio file to open, or the audio waveform\n",
      "    \n",
      "    verbose: bool\n",
      "        Whether to display the text being decoded to the console. If True, displays all the details,\n",
      "        If False, displays minimal details. If None, does not display anything\n",
      "    \n",
      "    temperature: Union[float, Tuple[float, ...]]\n",
      "        Temperature for sampling. It can be a tuple of temperatures, which will be successively used\n",
      "        upon failures according to either `compression_ratio_threshold` or `logprob_threshold`.\n",
      "    \n",
      "    compression_ratio_threshold: float\n",
      "        If the gzip compression ratio is above this value, treat as failed\n",
      "    \n",
      "    logprob_threshold: float\n",
      "        If the average log probability over sampled tokens is below this value, treat as failed\n",
      "    \n",
      "    no_speech_threshold: float\n",
      "        If the no_speech probability is higher than this value AND the average log probability\n",
      "        over sampled tokens is below `logprob_threshold`, consider the segment as silent\n",
      "    \n",
      "    condition_on_previous_text: bool\n",
      "        if True, the previous output of the model is provided as a prompt for the next window;\n",
      "        disabling may make the text inconsistent across windows, but the model becomes less prone to\n",
      "        getting stuck in a failure loop, such as repetition looping or timestamps going out of sync.\n",
      "    \n",
      "    word_timestamps: bool\n",
      "        Extract word-level timestamps using the cross-attention pattern and dynamic time warping,\n",
      "        and include the timestamps for each word in each segment.\n",
      "    \n",
      "    prepend_punctuations: str\n",
      "        If word_timestamps is True, merge these punctuation symbols with the next word\n",
      "    \n",
      "    append_punctuations: str\n",
      "        If word_timestamps is True, merge these punctuation symbols with the previous word\n",
      "    \n",
      "    initial_prompt: Optional[str]\n",
      "        Optional text to provide as a prompt for the first window. This can be used to provide, or\n",
      "        \"prompt-engineer\" a context for transcription, e.g. custom vocabularies or proper nouns\n",
      "        to make it more likely to predict those word correctly.\n",
      "    \n",
      "    decode_options: dict\n",
      "        Keyword arguments to construct `DecodingOptions` instances\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    A dictionary containing the resulting text (\"text\") and segment-level details (\"segments\"), and\n",
      "    the spoken language (\"language\"), which is detected when `decode_options[\"language\"]` is None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.transcribe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff79ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
