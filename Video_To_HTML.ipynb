{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056f5b2b",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- Allow resolution change to saved images to save space.\n",
    "- Pass language to Whisper???\n",
    "- Change from Whisper to Facebook's fairseq MMC? https://github.com/facebookresearch/fairseq/tree/main/examples/mms\n",
    "- Support audio only, like podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f2aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steph\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Steph\\anaconda3\\envs\\cuda11v7\\lib\\site-packages\\whisper\\timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import whisper\n",
    "import torch\n",
    "import moviepy.editor as mp\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import subprocess\n",
    "from datetime import timedelta\n",
    "from yattag import Doc\n",
    "import time\n",
    "\n",
    "\n",
    "ADD_FURIGANA = True\n",
    "VID_EXTS = ['.mp4','.avi','.ogv','.mkv','.webm']\n",
    "AUD_EXTS = ['.mp3']\n",
    "SUB_EXTS = ['.srt']\n",
    "WIDTH = 200\n",
    "src_dir = 'Input'\n",
    "out_dir = 'Output'\n",
    "files = [os.path.join(src_dir, f) for f in os.listdir(src_dir)]\n",
    "\n",
    "if ADD_FURIGANA:\n",
    "    from furigana.furigana import split_furigana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163e04c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Input\\\\2023年6月10日（土）「OK! Cozy up!週末増刊号」']\n"
     ]
    }
   ],
   "source": [
    "proj_files = [os.path.splitext(f)[0] for f in files if os.path.splitext(f)[-1] in VID_EXTS]\n",
    "\n",
    "# Add audio files if they weren't extracted from a video with the same name\n",
    "proj_files += [os.path.splitext(f)[0] for f in files if os.path.splitext(f)[-1] in AUD_EXTS and os.path.splitext(f)[0] not in proj_files]\n",
    "print(proj_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30b6082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_line_list(filename, encoding='utf-8-sig'):\n",
    "        line_list = []\n",
    "        with open(filename, 'r', encoding=encoding) as file:\n",
    "            for line in file:\n",
    "                line_list += [line.replace('\\n', '')]\n",
    "        return line_list\n",
    "\n",
    "def chunk_sub_idx_to_list(sub_line_list):\n",
    "        \"\"\"\n",
    "            Pass in a list where each line is a line in the subtitle file\n",
    "            Example:\n",
    "            ['1', '00:00:00,000 --> 00:00:04,430', 'おはようございます', '2', ...]\n",
    "\n",
    "            return a list where each list item is another list where each item is specific to its index\n",
    "            Example:\n",
    "            [['1', '00:00:00,000 --> 00:00:04,430', 'おはようございます'], ['2', ...], ...]\n",
    "        \"\"\"\n",
    "        lines_indexed = []\n",
    "        tmp = []\n",
    "        for i, line in enumerate(sub_line_list):\n",
    "            if line == '':\n",
    "                continue\n",
    "\n",
    "            tmp += [line]\n",
    "            if len(tmp) > 3:\n",
    "                digit, timestamp = tmp[-2:]\n",
    "                if digit.strip().isdigit() and '-->' in timestamp:\n",
    "                    lines_indexed += [tmp[:-2]]\n",
    "                    tmp = tmp[-2:]\n",
    "        return lines_indexed\n",
    "    \n",
    "def srt_time_to_seconds(time_line):\n",
    "    def timestr_to_sec(time_str):\n",
    "        h, m, s_str = time_str.split(':')\n",
    "        s, ms = s_str.split(',')\n",
    "        return int(h)*60*60 + int(m)*60 + int(s) + int(ms)/1000 \n",
    "\n",
    "    start_time_str, stop_time_str = time_line.split(' --> ')\n",
    "    start_time = timestr_to_sec(start_time_str)\n",
    "    stop_time = timestr_to_sec(stop_time_str)\n",
    "\n",
    "    return start_time, stop_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a33025bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_image(doc, image, idx, w=200, h=200):\n",
    "    basename = os.path.splitext(os.path.basename(image))[0]\n",
    "    with doc.tag('img', id=f'image_{idx}', src=image, alt=basename, width=w, height=h, klass=\"center\"):\n",
    "        pass # No content within this tag\n",
    "\n",
    "def add_audio_clip(doc, audio_file):\n",
    "    with doc.tag('audio', controls=True, klass=\"center\"):\n",
    "        doc.stag('source', src=os.path.basename(audio_file), type=\"audio/mpeg\")\n",
    "        doc.text('Your browser does not support the audio element.')\n",
    "\n",
    "def add_sub(doc, sub):\n",
    "    with doc.tag('div'):\n",
    "        doc.text(sub)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34dffbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_furigana(text):\n",
    "\n",
    "    w_furigana = ''\n",
    "    for pair in split_furigana(text):\n",
    "        if len(pair)==2:\n",
    "            kanji,hira = pair\n",
    "            w_furigana +=  f\"<ruby><rb>{kanji}</rb><rt>{hira}</rt></ruby>\"\n",
    "        else:\n",
    "            w_furigana += pair[0]\n",
    "    return w_furigana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0afdc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_html_doc(prj_dir, vid_file, aud_file, sub_file, base_filename, lines_indexed, audio_mode='normal', pad=0.5, line_sep=True):\n",
    "    \"\"\"\n",
    "    audio_mode: normal, off, only\n",
    "    \"\"\" \n",
    "    \n",
    "    prj_name = os.path.basename(prj_dir)\n",
    "    \n",
    "    # 1 Video Found    \n",
    "    if vid_file:\n",
    "        video_capture = cv2.VideoCapture(vid_file)\n",
    "    \n",
    "        if audio_mode == 'normal':\n",
    "            mp_video = mp.VideoFileClip(vid_file)\n",
    "    \n",
    "    # No Video Found\n",
    "    else:\n",
    "        if aud_file:\n",
    "            audio_mode = 'only'\n",
    "            mp_audio = mp.AudioFileClip(aud_file)\n",
    "        \n",
    "\n",
    "    doc, tag, text = Doc().tagtext()\n",
    "    \n",
    "    with tag('html'):\n",
    "        \n",
    "        doc.asis('<style>')\n",
    "        doc.text('div {text-align: center;} .center {display: block; margin-left: auto; margin-right: auto;}')\n",
    "        doc.text('''\n",
    "            body { background-color: #D8DFEE; }\n",
    "            h1, h2, h3 { color: #ABA8A9; }\n",
    "            .highlight { color: #CBF83E; }\n",
    "            div {text-align: center;} \n",
    "            .center {display: block; margin-left: auto; margin-right: auto;}\n",
    "        ''')\n",
    "        doc.asis('</style>')\n",
    "        \n",
    "        with tag('head'):\n",
    "            with tag('title'):\n",
    "                text(prj_name)\n",
    "                \n",
    "            # Image Size Control\n",
    "            with tag('script'):\n",
    "                doc.asis(\"\"\"\n",
    "                function updateImageSize() {\n",
    "                    var slider = document.getElementById(\"slider\");\n",
    "                    var images = document.getElementsByTagName(\"img\");\n",
    "                    for (var i = 0; i < images.length; i++) {\n",
    "                        images[i].style.width = slider.value + \"px\";\n",
    "                        images[i].style.height = \"auto\";\n",
    "                    }\n",
    "                }\n",
    "                \"\"\")\n",
    "        \n",
    "        with tag('body'):\n",
    "            \n",
    "            with doc.tag('div'):\n",
    "                with tag('label', ('for', 'slider')):\n",
    "                    text('Adjust Image Size')\n",
    "                with doc.tag('input', ('type', 'range'), ('min', '50'), ('max', '500'), ('value', '200'), \n",
    "                            ('id', 'slider'), ('oninput', 'updateImageSize()')):\n",
    "                    pass\n",
    "\n",
    "            for idx, r in enumerate(lines_indexed):\n",
    "                line_idx, time_str = r[:2]\n",
    "                sub_list = r[2:]\n",
    "\n",
    "                if ADD_FURIGANA:\n",
    "                    tmp = []\n",
    "                    for s in sub_list:\n",
    "                        try:\n",
    "                            tmp += [add_furigana(s)]\n",
    "                        except:\n",
    "                            tmp += [s]\n",
    "\n",
    "                    sub_list = tmp\n",
    "\n",
    "                start, stop = srt_time_to_seconds(time_str)\n",
    "                time_ms = int(1000*((stop - start)/2 + start))\n",
    "                \n",
    "                # Process Video-------------------\n",
    "                if audio_mode != 'only':\n",
    "                    video_capture.set(cv2.CAP_PROP_POS_MSEC, time_ms)\n",
    "                    success, image = video_capture.read()\n",
    "\n",
    "                    if success:\n",
    "                        new_filename = prj_name + '_' + str(time_ms) + '.jpg'\n",
    "                        path = os.path.join(prj_dir, new_filename)\n",
    "                        if not(os.path.exists(path)):\n",
    "                            cv2.imwrite(path, image)\n",
    "                            \n",
    "                        h, w = image.shape[:-1]\n",
    "                        ratio = h/w\n",
    "                        \n",
    "                        add_image(doc, new_filename, idx, w=WIDTH, h=int(WIDTH*ratio))\n",
    "                \n",
    "                # Add Subtitle---------------------\n",
    "                for s in sub_list:\n",
    "                    add_sub(doc, s)\n",
    "                            \n",
    "                # Process Audio--------------------\n",
    "                if audio_mode != 'off':                    \n",
    "                    new_filename = prj_name + '_' + str(time_ms) + '.mp3'\n",
    "                    path = os.path.join(prj_dir, new_filename)\n",
    "                    \n",
    "                    # Audio Only Mode\n",
    "                    if audio_mode == 'only':\n",
    "                        # Get audio subclip from audio file\n",
    "                        mp_audio.subclip(max(0, start - pad), stop+pad).write_audiofile(path, verbose=False, logger=None)\n",
    "                        \n",
    "                    # Normal Audio Mode\n",
    "                    else:\n",
    "                        # Get audio subclip from video file\n",
    "                        mp_video.subclip(max(0, start - pad), stop+pad).audio.write_audiofile(path, verbose=False, logger=None)\n",
    "                    \n",
    "                    add_audio_clip(doc, path)\n",
    "                    \n",
    "                if line_sep:\n",
    "                    doc.stag('hr')  # Add a horizontal line\n",
    "            \n",
    "    return doc.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b64b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = whisper.torch.device('cuda' if whisper.torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e6ade72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an mp3 from video file\n",
    "def extract_audio(vid_file, track_number=0): \n",
    "    def extract_ffmpeg(input_file, output_file, audio_track):\n",
    "        command = f'ffmpeg -i \"{input_file}\" -map 0:a:{audio_track} \"{output_file}\"'\n",
    "        result = subprocess.run(command, shell=True, text=True, capture_output=True)\n",
    "        print(\"stdout:\", result.stdout)\n",
    "        print(\"stderr:\", result.stderr)\n",
    "        \n",
    "    base_filename = os.path.splitext(vid_file)[0] # Remove ext\n",
    "\n",
    "    savename = base_filename + '.mp3'\n",
    "\n",
    "    # Default to using MoviePy\n",
    "    if track_number == 0:\n",
    "        v = mp.VideoFileClip(f)\n",
    "        v.audio.write_audiofile(savename)\n",
    "        \n",
    "    # Extract different track, need ffmpeg\n",
    "    else:\n",
    "        try:\n",
    "            extract_ffmpeg(vid_file, savename, track_number)\n",
    "        except Exception as e:\n",
    "            #print('Cant process ffmpeg. Ensure you have ffmpeg installed.')\n",
    "            print(f'FFMPEG Error: {e}')\n",
    "            \n",
    "    return savename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a2304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(transcription, base_filename):\n",
    "    savepath = base_filename + '.srt'\n",
    "    segments = transcription['segments']\n",
    "\n",
    "    for segment in segments:\n",
    "        startTime = str(0)+str(timedelta(seconds=int(segment['start'])))+',000'\n",
    "        endTime = str(0)+str(timedelta(seconds=int(segment['end'])))+',000'\n",
    "        text = segment['text']\n",
    "        if len(text) == 0:\n",
    "            continue\n",
    "        \n",
    "        segmentId = segment['id']+1\n",
    "        segment = f\"{segmentId}\\n{startTime} --> {endTime}\\n{text[1:] if text[0] is ' ' else text}\\n\\n\"\n",
    "\n",
    "        with open(savepath, 'a', encoding='utf-8') as srtFile:\n",
    "            srtFile.write(segment)\n",
    "            \n",
    "    return savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c171cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prj_media(base_filename):\n",
    "    has_ext = lambda exts: [f for f in files if f.startswith(base_filename) and os.path.splitext(f)[-1].lower() in exts]\n",
    "    \n",
    "    vid_files = has_ext(VID_EXTS)\n",
    "    aud_files = has_ext(AUD_EXTS)\n",
    "    sub_files = has_ext(SUB_EXTS)\n",
    "    \n",
    "    assert len(vid_files) <= 1, \"Multiple video extensions found w/ same base name.\"\n",
    "    assert len(aud_files) <= 1, \"Multiple audio extensions found w/ same base name.\"\n",
    "    \n",
    "    # 1 Video Found    \n",
    "    vid_file = vid_files[0] if len(vid_files) == 1 else None\n",
    "    aud_file = aud_files[0] if len(aud_files) == 1 else None\n",
    "    sub_file = sub_files[0] if len(sub_files) == 1 else None\n",
    "    \n",
    "    return vid_file, aud_file, sub_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "088c44b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: None, Input\\2023年6月10日（土）「OK! Cozy up!週末増刊号」.mp3, None\n",
      "Creating transcript using OpenAIs Whisper for Input\\2023年6月10日（土）「OK! Cozy up!週末増刊号」.mp3.\n",
      "Exporting subtitle.\n",
      "Sub File Extracted: Input\\2023年6月10日（土）「OK! Cozy up!週末増刊号」.srt\n",
      "Generating Audio Visual HTML Page\n",
      "Finished processing Input\\2023年6月10日（土）「OK! Cozy up!週末増刊号」\n",
      "Total processing time: 435.4954299926758\n"
     ]
    }
   ],
   "source": [
    "TRACK_NUMBER = 2\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for prj in proj_files:    \n",
    "    vid_file, aud_file, sub_file = get_prj_media(prj)\n",
    "    print(f'Files: {vid_file}, {aud_file}, {sub_file}')\n",
    "    \n",
    "    # if audio doesnt exist extract it from video\n",
    "    if aud_file == None:\n",
    "        if vid_file:\n",
    "            print(f'Extracting mp3 from {prj}...')\n",
    "            aud_file = extract_audio(vid_file, track_number=TRACK_NUMBER)\n",
    "            print(f'Audio File Extracted: {aud_file}')\n",
    "            print('Finished extracting audio.')\n",
    "    \n",
    "    # Use subtitle file doesn't exists create it\n",
    "    if sub_file == None:\n",
    "        if os.path.exists(aud_file):\n",
    "            print(f'Creating transcript using OpenAIs Whisper for {aud_file}.')\n",
    "            \n",
    "            model = whisper.load_model(\"base\")\n",
    "            transcription = model.transcribe(aud_file)\n",
    "            \n",
    "            print('Exporting subtitle.')\n",
    "            sub_file = transcribe_audio(transcription, prj)\n",
    "            print(f'Sub File Extracted: {sub_file}')\n",
    "        else:\n",
    "            print(f'Error. Audio file {aud_file} not found.')\n",
    "        \n",
    "    # Check if subtitle exists\n",
    "    if os.path.exists(sub_file):\n",
    "        print('Generating Audio Visual HTML Page')\n",
    "        \n",
    "        prj_name = os.path.basename(prj).replace(' ','_')\n",
    "        prj_dir = os.path.join(out_dir, prj_name)\n",
    "        if not(os.path.exists(prj_dir)):\n",
    "            os.mkdir(prj_dir)\n",
    "\n",
    "        line_list = file_to_line_list(sub_file)\n",
    "        lines_indexed = chunk_sub_idx_to_list(line_list)\n",
    "\n",
    "        html = build_html_doc(prj_dir, vid_file, aud_file, sub_file, prj, lines_indexed)\n",
    "\n",
    "        save_path = os.path.join(prj_dir, prj_name + '.html')\n",
    "        \n",
    "        with open(save_path, 'w', encoding='utf-8') as html_file:\n",
    "            html_file.write(html)\n",
    "\n",
    "        print(f'Finished processing {prj}')\n",
    "\n",
    "    else:\n",
    "        print(f'Error. Subtitle file {sub_file} not found.')\n",
    "        \n",
    "print(f'Total processing time: {time.time() - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e2c766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Input\\\\2023年6月10日（土）「OK! Cozy up!週末増刊号」.srt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d551d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
